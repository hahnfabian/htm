{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de81cd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/__init__.py:149\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# NOTE: to be revisited following future namespace cleanup.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# See gh-14454 and gh-15672 for discussion.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/lib/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Private submodules\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# load module names. See https://github.com/networkx/networkx/issues/5838\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_check\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index_tricks\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_base\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nanfunctions\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/lib/index_tricks.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumeric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScalarType, array\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumerictypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issubdtype\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatrixlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmatrixlib\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m diff\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ravel_multi_index, unravel_index\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/matrixlib/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Sub-package containing the matrix class and related functions.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defmatrix\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m defmatrix\u001b[38;5;241m.\u001b[39m__all__\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/matrixlib/defmatrix.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumeric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concatenate, isscalar\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# While not in __all__, matrix_power used to be defined here, so we import\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# it for backward compatibility.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix_power\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_from_string\u001b[39m(data):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/linalg/__init__.py:73\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m``numpy.linalg``\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# To get sub-modules\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     76\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39m__all__\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/linalg/linalg.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtwodim_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m triu, eye\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _umath_linalg\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NDArray\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEigResult\u001b[39;00m(NamedTuple):\n\u001b[1;32m     40\u001b[0m     eigenvalues: NDArray[Any]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/_typing/__init__.py:107\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nested_sequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     _NestedSequence \u001b[38;5;28;01mas\u001b[39;00m _NestedSequence,\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nbit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     _NBitByte \u001b[38;5;28;01mas\u001b[39;00m _NBitByte,\n\u001b[1;32m     97\u001b[0m     _NBitShort \u001b[38;5;28;01mas\u001b[39;00m _NBitShort,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     _NBitLongDouble \u001b[38;5;28;01mas\u001b[39;00m _NBitLongDouble,\n\u001b[1;32m    106\u001b[0m )\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_char_codes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m     _BoolCodes \u001b[38;5;28;01mas\u001b[39;00m _BoolCodes,\n\u001b[1;32m    109\u001b[0m     _UInt8Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt8Codes,\n\u001b[1;32m    110\u001b[0m     _UInt16Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt16Codes,\n\u001b[1;32m    111\u001b[0m     _UInt32Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt32Codes,\n\u001b[1;32m    112\u001b[0m     _UInt64Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt64Codes,\n\u001b[1;32m    113\u001b[0m     _Int8Codes \u001b[38;5;28;01mas\u001b[39;00m _Int8Codes,\n\u001b[1;32m    114\u001b[0m     _Int16Codes \u001b[38;5;28;01mas\u001b[39;00m _Int16Codes,\n\u001b[1;32m    115\u001b[0m     _Int32Codes \u001b[38;5;28;01mas\u001b[39;00m _Int32Codes,\n\u001b[1;32m    116\u001b[0m     _Int64Codes \u001b[38;5;28;01mas\u001b[39;00m _Int64Codes,\n\u001b[1;32m    117\u001b[0m     _Float16Codes \u001b[38;5;28;01mas\u001b[39;00m _Float16Codes,\n\u001b[1;32m    118\u001b[0m     _Float32Codes \u001b[38;5;28;01mas\u001b[39;00m _Float32Codes,\n\u001b[1;32m    119\u001b[0m     _Float64Codes \u001b[38;5;28;01mas\u001b[39;00m _Float64Codes,\n\u001b[1;32m    120\u001b[0m     _Complex64Codes \u001b[38;5;28;01mas\u001b[39;00m _Complex64Codes,\n\u001b[1;32m    121\u001b[0m     _Complex128Codes \u001b[38;5;28;01mas\u001b[39;00m _Complex128Codes,\n\u001b[1;32m    122\u001b[0m     _ByteCodes \u001b[38;5;28;01mas\u001b[39;00m _ByteCodes,\n\u001b[1;32m    123\u001b[0m     _ShortCodes \u001b[38;5;28;01mas\u001b[39;00m _ShortCodes,\n\u001b[1;32m    124\u001b[0m     _IntCCodes \u001b[38;5;28;01mas\u001b[39;00m _IntCCodes,\n\u001b[1;32m    125\u001b[0m     _IntPCodes \u001b[38;5;28;01mas\u001b[39;00m _IntPCodes,\n\u001b[1;32m    126\u001b[0m     _IntCodes \u001b[38;5;28;01mas\u001b[39;00m _IntCodes,\n\u001b[1;32m    127\u001b[0m     _LongLongCodes \u001b[38;5;28;01mas\u001b[39;00m _LongLongCodes,\n\u001b[1;32m    128\u001b[0m     _UByteCodes \u001b[38;5;28;01mas\u001b[39;00m _UByteCodes,\n\u001b[1;32m    129\u001b[0m     _UShortCodes \u001b[38;5;28;01mas\u001b[39;00m _UShortCodes,\n\u001b[1;32m    130\u001b[0m     _UIntCCodes \u001b[38;5;28;01mas\u001b[39;00m _UIntCCodes,\n\u001b[1;32m    131\u001b[0m     _UIntPCodes \u001b[38;5;28;01mas\u001b[39;00m _UIntPCodes,\n\u001b[1;32m    132\u001b[0m     _UIntCodes \u001b[38;5;28;01mas\u001b[39;00m _UIntCodes,\n\u001b[1;32m    133\u001b[0m     _ULongLongCodes \u001b[38;5;28;01mas\u001b[39;00m _ULongLongCodes,\n\u001b[1;32m    134\u001b[0m     _HalfCodes \u001b[38;5;28;01mas\u001b[39;00m _HalfCodes,\n\u001b[1;32m    135\u001b[0m     _SingleCodes \u001b[38;5;28;01mas\u001b[39;00m _SingleCodes,\n\u001b[1;32m    136\u001b[0m     _DoubleCodes \u001b[38;5;28;01mas\u001b[39;00m _DoubleCodes,\n\u001b[1;32m    137\u001b[0m     _LongDoubleCodes \u001b[38;5;28;01mas\u001b[39;00m _LongDoubleCodes,\n\u001b[1;32m    138\u001b[0m     _CSingleCodes \u001b[38;5;28;01mas\u001b[39;00m _CSingleCodes,\n\u001b[1;32m    139\u001b[0m     _CDoubleCodes \u001b[38;5;28;01mas\u001b[39;00m _CDoubleCodes,\n\u001b[1;32m    140\u001b[0m     _CLongDoubleCodes \u001b[38;5;28;01mas\u001b[39;00m _CLongDoubleCodes,\n\u001b[1;32m    141\u001b[0m     _DT64Codes \u001b[38;5;28;01mas\u001b[39;00m _DT64Codes,\n\u001b[1;32m    142\u001b[0m     _TD64Codes \u001b[38;5;28;01mas\u001b[39;00m _TD64Codes,\n\u001b[1;32m    143\u001b[0m     _StrCodes \u001b[38;5;28;01mas\u001b[39;00m _StrCodes,\n\u001b[1;32m    144\u001b[0m     _BytesCodes \u001b[38;5;28;01mas\u001b[39;00m _BytesCodes,\n\u001b[1;32m    145\u001b[0m     _VoidCodes \u001b[38;5;28;01mas\u001b[39;00m _VoidCodes,\n\u001b[1;32m    146\u001b[0m     _ObjectCodes \u001b[38;5;28;01mas\u001b[39;00m _ObjectCodes,\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scalars\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    149\u001b[0m     _CharLike_co \u001b[38;5;28;01mas\u001b[39;00m _CharLike_co,\n\u001b[1;32m    150\u001b[0m     _BoolLike_co \u001b[38;5;28;01mas\u001b[39;00m _BoolLike_co,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     _VoidLike_co \u001b[38;5;28;01mas\u001b[39;00m _VoidLike_co,\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    161\u001b[0m     _Shape \u001b[38;5;28;01mas\u001b[39;00m _Shape,\n\u001b[1;32m    162\u001b[0m     _ShapeLike \u001b[38;5;28;01mas\u001b[39;00m _ShapeLike,\n\u001b[1;32m    163\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/_typing/_char_codes.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m _Float64Codes \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=f8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<f8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>f8\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m _Complex64Codes \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=c8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<c8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>c8\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m _Complex128Codes \u001b[38;5;241m=\u001b[39m \u001b[43mLiteral\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomplex128\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m=c16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<c16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>c16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m _ByteCodes \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbyte\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>b\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     23\u001b[0m _ShortCodes \u001b[38;5;241m=\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=h\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<h\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>h\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:495\u001b[0m, in \u001b[0;36m_LiteralSpecialForm.__getitem__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameters, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    494\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m (parameters,)\n\u001b[0;32m--> 495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:362\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:747\u001b[0m, in \u001b[0;36mLiteral\u001b[0;34m(self, *parameters)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# unhashable parameters\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_LiteralGenericAlias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:1362\u001b[0m, in \u001b[0;36m_GenericAlias.__init__\u001b[0;34m(self, origin, args, inst, name, _paramspec_tvars)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, origin, args, \u001b[38;5;241m*\u001b[39m, inst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1361\u001b[0m              _paramspec_tvars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1364\u001b[0m         args \u001b[38;5;241m=\u001b[39m (args,)\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:1266\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__init__\u001b[0;34m(self, origin, inst, name)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, origin, \u001b[38;5;241m*\u001b[39m, inst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inst\u001b[49m \u001b[38;5;241m=\u001b[39m inst\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__ \u001b[38;5;241m=\u001b[39m origin\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:1305\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__setattr__\u001b[0;34m(self, attr, val)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr, val):\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_dunder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_inst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_nparams\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1306\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_paramspec_tvars\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m   1307\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(attr, val)\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/LIR2/lib/python3.11/typing.py:1253\u001b[0m, in \u001b[0;36m_is_dunder\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_dunder\u001b[39m(attr):\n\u001b[0;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from util import TokenMergeBuffer, TokenUnmergeBuffer, EarlyStopper\n",
    "from models import AE_no_lift\n",
    "from toy_data.environments import RandomWalker\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e850c1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a51c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "walker = RandomWalker(\n",
    "    n=1000, \n",
    "    length=10, \n",
    "    dim=2, \n",
    "    step_scale=0.1, \n",
    "    init=\"normal\", \n",
    "    drift=\"centre\").generate()\n",
    "\n",
    "dataset = torch.tensor(walker.data, dtype=torch.float32)\n",
    "\n",
    "train_pct = 0.8\n",
    "train_size = int(train_pct * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a7910",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_merge_event(\n",
    "    tokens_2d_step1,          # (L1, 2) coords BEFORE merge #1\n",
    "    prob_matrix1,             # (L1, L1) softmax AFTER masking/softmax\n",
    "    chosen1,                  # (i1, j1)\n",
    "    tokens_2d_step2,          # (L2, 2) coords AFTER merge #1, BEFORE merge #2\n",
    "    prob_matrix2,             # (L2, L2) softmax at step 2\n",
    "    chosen2,                  # (i2, j2)\n",
    "    figsize=(12, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes exactly two merge steps:\n",
    "    Merge #1 probability matrix + chosen pair\n",
    "    Merge #2 probability matrix + chosen pair\n",
    "    Final token 2-D scatter after the second merge.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    # ---- Helper to render each probability map ----\n",
    "    def render_prob(ax, P, chosen, title):\n",
    "        P = P.copy()\n",
    "        np.fill_diagonal(P, np.nan)              # mask diagonal\n",
    "        \n",
    "        im = ax.imshow(P, interpolation='nearest', cmap='viridis')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # highlight chosen pair\n",
    "        i, j = chosen\n",
    "        ax.scatter([j], [i], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "        ax.scatter([i], [j], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "\n",
    "        # nice grid\n",
    "        ax.set_xticks(np.arange(P.shape[1]) + 0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(P.shape[0]) + 0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linewidth=0.4)\n",
    "        ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "        # colorbar\n",
    "        fig.colorbar(im, ax=ax, fraction=0.10, pad=0.03)\n",
    "\n",
    "    # ---- Panel 1: merge #1 probability map ----\n",
    "    render_prob(axes[0], prob_matrix1, chosen1, \"Merge #1 Softmax\")\n",
    "\n",
    "    # ---- Panel 2: merge #2 probability map ----\n",
    "    render_prob(axes[1], prob_matrix2, chosen2, \"Merge #2 Softmax\")\n",
    "\n",
    "    # ---- Panel 3: final token positions after merge #2 ----\n",
    "    ax = axes[2]\n",
    "    ax.scatter(tokens_2d_step2[:,0], tokens_2d_step2[:,1],\n",
    "               s=40, color=\"black\")\n",
    "\n",
    "    # highlight merged token #2\n",
    "    mi2, mj2 = chosen2\n",
    "    merged_xy = tokens_2d_step2  # user passes correct coords after merge #2\n",
    "\n",
    "    # You can choose to mark the newly created token with a star if desired\n",
    "    # ax.scatter([merged_xy[-1,0]], [merged_xy[-1,1]],\n",
    "    #            s=200, marker=\"*\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "    ax.set_title(\"Tokens After Merge #2\")\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e904a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_merge_event_full(tokens_2d, prob_matrix, chosen_i, chosen_j,\n",
    "                     orig_traj, recon_traj, merged_token_2d=None,\n",
    "                     title_positions=\"Token positions\",\n",
    "                     title_matrix=\"Softmax merge probs\",\n",
    "                     title_recon=\"Original (blue), Recon (red)\",\n",
    "                     highlight_recon_idx=None):\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Convert to numpy\n",
    "    # ------------------------------------\n",
    "    if hasattr(tokens_2d, \"cpu\"):\n",
    "        tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "    if hasattr(prob_matrix, \"cpu\"):\n",
    "        prob_matrix = prob_matrix.detach().cpu().numpy()\n",
    "    if hasattr(orig_traj, \"cpu\"):\n",
    "        orig_traj = orig_traj.detach().cpu().numpy()\n",
    "    if hasattr(recon_traj, \"cpu\"):\n",
    "        recon_traj = recon_traj.detach().cpu().numpy()\n",
    "\n",
    "    # Create **3** subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    N = tokens_2d.shape[0]\n",
    "\n",
    "    # ========================================================\n",
    "    # 1 — Softmax matrix\n",
    "    # ========================================================\n",
    "    np.fill_diagonal(prob_matrix, np.nan)\n",
    "    ax = axes[0]\n",
    "    im = ax.imshow(prob_matrix, interpolation=\"nearest\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "    ax.set_title(title_matrix)\n",
    "    ax.set_xlabel(\"Token index\")\n",
    "    ax.set_ylabel(\"Token index\")\n",
    "\n",
    "    ax.set_xticks(range(N))\n",
    "    ax.set_yticks(range(N))\n",
    "\n",
    "    # highlight chosen merge pair\n",
    "    ax.scatter([chosen_j], [chosen_i], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "    ax.scatter([chosen_i], [chosen_j], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"black\", linewidth=0.2)\n",
    "\n",
    "    # ========================================================\n",
    "    # 2 — Token positions + merged token\n",
    "    # ========================================================\n",
    "    ax = axes[1]\n",
    "    ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "\n",
    "    for idx, (x,y) in enumerate(tokens_2d):\n",
    "        ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "    # highlight original pair\n",
    "    ax.scatter(\n",
    "        tokens_2d[[chosen_i, chosen_j],0],\n",
    "        tokens_2d[[chosen_i, chosen_j],1],\n",
    "        s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2\n",
    "    )\n",
    "\n",
    "    # merged token (star)\n",
    "    # if merged_token_2d is not None:\n",
    "    #     if hasattr(merged_token_2d, \"cpu\"):\n",
    "    #         merged_token_2d = merged_token_2d.detach().cpu().numpy()\n",
    "\n",
    "    #     ax.scatter(\n",
    "    #         [merged_token_2d[0]], [merged_token_2d[1]],\n",
    "    #         s=220, marker=\"*\", color=\"red\", linewidth=2,\n",
    "    #     )\n",
    "\n",
    "    ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"dim 1\")\n",
    "    ax.set_ylabel(\"dim 2\")\n",
    "\n",
    "    # ========================================================\n",
    "    # 3 — Original vs Reconstruction trajectory\n",
    "    # ========================================================\n",
    "    ax = axes[2]\n",
    "\n",
    "    \n",
    "\n",
    "    # draw original trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(orig_traj[:-1], orig_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"blue\", linewidth=1)\n",
    "\n",
    "    # draw reconstructed trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(recon_traj[:-1], recon_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"red\", linewidth=1)\n",
    "\n",
    "    if highlight_recon_idx is not None:\n",
    "        i, j = highlight_recon_idx\n",
    "        ax.scatter([recon_traj[i,0]], [recon_traj[i,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "        ax.scatter([recon_traj[j,0]], [recon_traj[j,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(title_recon)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2aa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_softmax_to_buffer(prob_matrix, active_idx, full_N, removed_pairs):\n",
    "    \"\"\"\n",
    "    prob_matrix: (n_active, n_active) softmax matrix\n",
    "    active_idx: indices in buffer corresponding to rows/cols of prob_matrix\n",
    "    full_N: total buffer size BEFORE merge\n",
    "    removed_pairs: indices that were merged and removed in that step\n",
    "    \"\"\"\n",
    "    out = np.full((full_N, full_N), np.nan)\n",
    "\n",
    "    # Fill values for still-active tokens\n",
    "    for i_local, i_global in enumerate(active_idx):\n",
    "        for j_local, j_global in enumerate(active_idx):\n",
    "            out[i_global, j_global] = prob_matrix[i_local, j_local]\n",
    "\n",
    "    # Insert NaNs for removed tokens\n",
    "    for dead in removed_pairs:\n",
    "        out[dead, :] = np.nan\n",
    "        out[:, dead] = np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_2_merges(\n",
    "        tokens_1, \n",
    "        tokens_2, \n",
    "        prob_matrix_1, \n",
    "        prob_matrix_2,\n",
    "        active_idx_1,\n",
    "        active_idx_2,\n",
    "        removed_1,\n",
    "        removed_2,\n",
    "        orig_traj_1,\n",
    "        orig_traj_2,\n",
    "        recon_traj_1,\n",
    "        recon_traj_2,\n",
    "        merged_token_1,\n",
    "        merged_token_2\n",
    "    ):\n",
    "    \"\"\"\n",
    "    tokens_1, tokens_2: (n_active,2) 2D coordinates of tokens before each merge\n",
    "    prob_matrix_1, prob_matrix_2: softmax matrices in ACTIVE index space\n",
    "    active_idx_1, active_idx_2: active token -> buffer index mapping\n",
    "    removed_1, removed_2: the pair removed at each step (global buffer indices)\n",
    "    merged_token_1, merged_token_2: (2,) 2D coords of new merged token\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine full size\n",
    "    full_N = max(active_idx_1.max(), active_idx_2.max()).item() + 1\n",
    "\n",
    "    # --- Build full softmax matrices with NaNs inserted ---\n",
    "    prob_full_1 = remap_softmax_to_buffer(prob_matrix_1, active_idx_1, full_N, removed_1)\n",
    "    prob_full_2 = remap_softmax_to_buffer(prob_matrix_2, active_idx_2, full_N, removed_2)\n",
    "\n",
    "    # --- Grid of 2 steps ---\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(17,10))\n",
    "\n",
    "    # ============ STEP 1 ============\n",
    "    _ = plot_merge_event_full(\n",
    "        tokens_2d=tokens_1,\n",
    "        prob_matrix=prob_full_1,\n",
    "        chosen_i=removed_1[0], chosen_j=removed_1[1],\n",
    "        orig_traj=orig_traj_1,\n",
    "        recon_traj=recon_traj_1,\n",
    "        merged_token_2d=merged_token_1,\n",
    "        title_positions=\"Step 1 token positions\",\n",
    "        title_matrix=\"Step 1 softmax (full buffer space)\",\n",
    "        title_recon=\"Step 1 trajectories\",\n",
    "    )\n",
    "\n",
    "    # move result onto axes[0]\n",
    "    fig.axes[-1].remove()   # remove auto-created fig from plot_merge_event_full\n",
    "    for ax_from, ax_to in zip(plt.gcf().axes[-3:], axes[0]):\n",
    "        fig.axes.remove(ax_from)\n",
    "        fig.add_axes(ax_to)\n",
    "        ax_to = ax_from\n",
    "\n",
    "    # ============ STEP 2 ============\n",
    "    _ = plot_merge_event_full(\n",
    "        tokens_2d=tokens_2,\n",
    "        prob_matrix=prob_full_2,\n",
    "        chosen_i=removed_2[0], chosen_j=removed_2[1],\n",
    "        orig_traj=orig_traj_2,\n",
    "        recon_traj=recon_traj_2,\n",
    "        merged_token_2d=merged_token_2,\n",
    "        title_positions=\"Step 2 token positions\",\n",
    "        title_matrix=\"Step 2 softmax (full buffer space)\",\n",
    "        title_recon=\"Step 2 trajectories\",\n",
    "    )\n",
    "\n",
    "    # move onto axes[1]\n",
    "    fig.axes[-1].remove()\n",
    "    for ax_from, ax_to in zip(plt.gcf().axes[-3:], axes[1]):\n",
    "        fig.axes.remove(ax_from)\n",
    "        fig.add_axes(ax_to)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_merge_depth(curr_epoch, total_epochs, max_depth, power=2.0):\n",
    "    progress = curr_epoch / total_epochs\n",
    "    scaled = progress ** (1.0 / power)     # fast rise\n",
    "    depth = int(scaled * max_depth)        # quantize into buckets\n",
    "    return min(max(depth, 1), max_depth)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device, policy, current_depth, criterion, temperature=1):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        raw_tokens = batch.to(device)\n",
    "        buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "        while buf.can_merge(current_depth):\n",
    "            active = buf.get_active_tokens()\n",
    "            B, N, D = active.shape\n",
    "            pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "            num_pairs = pair_idx.shape[0]\n",
    "\n",
    "            t1 = active[:, pair_idx[:, 0], :]\n",
    "            t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "            t1 = t1.detach()\n",
    "            t2 = t2.detach()\n",
    "\n",
    "            x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "            x_hat = model(x)\n",
    "\n",
    "            t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "            mse = nn.MSELoss(reduction=\"none\")\n",
    "            recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "            recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "            loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "            if policy == \"argmin\":\n",
    "                chosen = loss_per_pair.argmin(dim=1)\n",
    "            elif policy == \"softmax\":\n",
    "                probs = torch.softmax(-loss_per_pair / temperature, dim=1)\n",
    "                chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "            elif policy == \"uniform\":\n",
    "                chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown policy {policy}\")\n",
    "\n",
    "            local_t1_idx = pair_idx[chosen, 0]\n",
    "            local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "            chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "            chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "            chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "            merged_tokens = model.encode(chosen_x)\n",
    "\n",
    "            buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "        buffer = buf.buffer\n",
    "        merge_history = buf.get_merge_history()\n",
    "        active_mask = buf.get_active_mask()\n",
    "        n_original_tokens = raw_tokens.shape[1]    \n",
    "        unmerge_buf = TokenUnmergeBuffer(buffer=buffer, active_mask=active_mask, merges=merge_history, n_original=n_original_tokens) \n",
    "\n",
    "        while not unmerge_buf.is_done():\n",
    "            merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "            pred = model.decode(merged_token)\n",
    "            t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "            unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "        \n",
    "        reconstructed = unmerge_buf.get_original_tokens()\n",
    "\n",
    "        loss = criterion(reconstructed, raw_tokens)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        config,\n",
    "        device,\n",
    "        checkpoint_path,\n",
    "        max_depth,\n",
    "        ):\n",
    "    \n",
    "    model.to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"random-walker\",\n",
    "        config=config,\n",
    "        name=config.model_name\n",
    "    )\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        orig_samples = None\n",
    "        recon_samples = None\n",
    "\n",
    "        capture_done = False\n",
    "        merge_viz_events = []\n",
    "        merge_figs = []\n",
    "        recon_fig = None\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            raw_tokens = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "\n",
    "            if orig_samples is None:\n",
    "                orig_samples = raw_tokens\n",
    "\n",
    "            buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "            # current_depth = get_merge_depth(epoch+1, config.epochs, config.max_depth)\n",
    "            current_depth = max_depth\n",
    "            \n",
    "\n",
    "            while buf.can_merge(current_depth):\n",
    "                active = buf.get_active_tokens()  # (B, N, D)\n",
    "                B, N, D = active.shape\n",
    "\n",
    "                pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "                num_pairs = pair_idx.shape[0]\n",
    "\n",
    "                t1 = active[:, pair_idx[:, 0], :]\n",
    "                t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "                # TODO: fix detaching\n",
    "                # t1 = t1.detach()\n",
    "                # t2 = t2.detach()\n",
    "\n",
    "                x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "                x_hat = model(x)\n",
    "\n",
    "                t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "                mse = nn.MSELoss(reduction=\"none\")\n",
    "                recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "                recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "                loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "                policy = config.sampling_policy\n",
    "                if policy == \"argmin\":\n",
    "                    chosen = loss_per_pair.argmin(dim=1)\n",
    "                elif policy == \"uniform\":\n",
    "                    chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "                elif policy == \"softmax\":\n",
    "                    probs = torch.softmax(-loss_per_pair / config.temperature, dim=1)\n",
    "                    chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "\n",
    "                    if not capture_done:\n",
    "                        b = 0  # pick one sample to visualize\n",
    "\n",
    "                        chosen_i = pair_idx[chosen[b], 0].item()\n",
    "                        chosen_j = pair_idx[chosen[b], 1].item()\n",
    "\n",
    "                        token_prob_matrix = torch.zeros(N, N, device=device)\n",
    "                        for p in range(num_pairs):\n",
    "                            i = pair_idx[p, 0].item()\n",
    "                            j = pair_idx[p, 1].item()\n",
    "                            token_prob_matrix[i, j] = probs[b, p]\n",
    "                            token_prob_matrix[j, i] = probs[b, p]\n",
    "                        tokens_2d = active[b, :, :].detach().cpu()\n",
    "\n",
    "                        merge_viz_events.append({\n",
    "                            \"tokens_2d\": tokens_2d,\n",
    "                            \"prob_matrix\": token_prob_matrix.detach().cpu(),\n",
    "                            \"chosen_i\": chosen_i,\n",
    "                            \"chosen_j\": chosen_j,\n",
    "                            \"local_t1_idx\": None,    # fill later\n",
    "                            \"local_t2_idx\": None,\n",
    "                            \"merged_token_2d\": None  # fill after merge\n",
    "                        })\n",
    "\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown sampling policy: {policy}\")\n",
    "                \n",
    "                local_t1_idx = pair_idx[chosen, 0]\n",
    "                local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "                chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "                chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "                 \n",
    "                chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "                merged_tokens = model.encode(chosen_x)\n",
    "                buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "                if len(merge_viz_events) <= 2:   # store only first 2 merges\n",
    "                    merge_viz_events[-1][\"local_t1_idx\"] = local_t1_idx[b].item()\n",
    "                    merge_viz_events[-1][\"local_t2_idx\"] = local_t2_idx[b].item()\n",
    "                    merge_viz_events[-1][\"merged_token_2d\"] = merged_tokens[b, :2].detach().cpu()\n",
    "\n",
    "            buffer = buf.buffer\n",
    "            merge_history = buf.get_merge_history()\n",
    "            active_mask = buf.get_active_mask()\n",
    "            n_original_tokens = raw_tokens.shape[1]\n",
    "\n",
    "            unmerge_buf = TokenUnmergeBuffer(buffer=buffer,\n",
    "                                             active_mask=active_mask,\n",
    "                                             merges=merge_history,\n",
    "                                             n_original=n_original_tokens)\n",
    "\n",
    "            \n",
    "            while not unmerge_buf.is_done():\n",
    "                merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "                pred = model.decode(merged_token)\n",
    "                t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "                unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "            reconstructed = unmerge_buf.get_original_tokens()\n",
    "            \n",
    "            if recon_fig is None:\n",
    "                recon_fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "                recon_fig.set_title(f\"Original (red), Recon (blue)\")\n",
    "\n",
    "                for i in range(5):\n",
    "                    sample1 = reconstructed[i].detach().cpu()\n",
    "                    sample2 = raw_tokens[i].detach().cpu()\n",
    "\n",
    "                    axes[i].scatter(sample1[:, 0], sample1[:, 1], color='blue', alpha=0.7)\n",
    "                    axes[i].scatter(sample2[:, 0], sample2[:, 1], color='red', alpha=0.7)\n",
    "                    \n",
    "                    # axes[i].set_title(f\"{sample1.shape}\")\n",
    "                    axes[i].set_xlabel(\"x\")\n",
    "                    axes[i].set_ylabel(\"y\")\n",
    "\n",
    "\n",
    "            if not capture_done:\n",
    "                if len(merge_viz_events) >= 1:\n",
    "                    orig_traj = raw_tokens[b, :, :2].detach().cpu()\n",
    "                    recon_traj = reconstructed[b, :, :2].detach().cpu()\n",
    "\n",
    "                    # print(orig_traj-recon_traj)\n",
    "\n",
    "                    # --- For each merge event we stored ---\n",
    "                    for k, event in enumerate(merge_viz_events[:2]):\n",
    "                        fig = plot_merge_event_full(\n",
    "                            tokens_2d=event[\"tokens_2d\"],\n",
    "                            prob_matrix=event[\"prob_matrix\"],\n",
    "                            chosen_i=event[\"chosen_i\"],\n",
    "                            chosen_j=event[\"chosen_j\"],\n",
    "                            orig_traj=orig_traj,\n",
    "                            recon_traj=recon_traj,\n",
    "                            merged_token_2d=event[\"merged_token_2d\"],\n",
    "                            highlight_recon_idx=(event[\"local_t1_idx\"], event[\"local_t2_idx\"]),\n",
    "                            title_matrix=f\"Softmax merge probs (step {k+1})\",\n",
    "                            title_positions=f\"Token positions (step {k+1})\"\n",
    "                        )\n",
    "                        merge_figs.append(fig)\n",
    "                        plt.close(fig)\n",
    "\n",
    "                capture_done = True\n",
    "\n",
    "\n",
    "            loss = criterion(reconstructed, raw_tokens)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        val_loss = evaluate(model, val_loader, device, config.sampling_policy, current_depth, criterion, config.temperature)\n",
    "\n",
    "                \n",
    "        if checkpoint_path and val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        log_dict = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"epoch\": epoch,\n",
    "        \"merge_depth\": current_depth,\n",
    "        \"merge_event_step_1\": wandb.Image(merge_figs[0]),\n",
    "        # \"merge_event_step_2\": wandb.Image(merge_figs[1]),\n",
    "        \"recon_fig\": wandb.Image(recon_fig)\n",
    "        }\n",
    "        plt.close(recon_fig)\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "        \n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d359915",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/export/home/2jhahn/htm/wandb/run-20251205_024535-pbvub4mu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fabianhahn/random-walker/runs/pbvub4mu' target=\"_blank\">softmax-0.5-lr-0.0001-merges-1</a></strong> to <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fabianhahn/random-walker/runs/pbvub4mu' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker/runs/pbvub4mu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_dim = 2\n",
    "latent_dim = 2\n",
    "hidden_dim = 128\n",
    "merges = 1\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    sampling_policy=\"softmax\",\n",
    "    batch_size=128,\n",
    "    device=device,\n",
    "    model_name=f\"softmax-0.5-lr-{1e-4}-merges-{merges}\",\n",
    "    max_depth=merges,\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "model = AE_no_lift(\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    latent_dim=latent_dim\n",
    "    ).to(device)\n",
    "\n",
    "train(model, train_loader, val_loader, config, device, checkpoint_path=f\"./checkpoints/{config.model_name}.pth\", max_depth=merges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
