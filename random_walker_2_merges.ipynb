{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de81cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from util import TokenMergeBuffer, TokenUnmergeBuffer, EarlyStopper\n",
    "from models import AE_no_lift\n",
    "from toy_data.environments import RandomWalker\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e850c1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a51c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7607, -1.1760],\n",
       "        [-0.7085, -1.0405],\n",
       "        [-0.8121, -1.0314],\n",
       "        [-0.9543, -1.0352],\n",
       "        [-0.9117, -0.9701],\n",
       "        [-0.7913, -0.8693],\n",
       "        [-0.6610, -0.9800],\n",
       "        [-0.7984, -0.9487],\n",
       "        [-0.8178, -1.1948],\n",
       "        [-0.8337, -1.1079]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "walker = RandomWalker(\n",
    "    n=1000, \n",
    "    length=10, \n",
    "    dim=2, \n",
    "    step_scale=0.1, \n",
    "    init=\"normal\", \n",
    "    drift=\"centre\").generate()\n",
    "\n",
    "dataset = torch.tensor(walker.data, dtype=torch.float32)\n",
    "\n",
    "train_pct = 0.8\n",
    "train_size = int(train_pct * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a7910",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_merge_event(\n",
    "    tokens_2d_step1,          # (L1, 2) coords BEFORE merge #1\n",
    "    prob_matrix1,             # (L1, L1) softmax AFTER masking/softmax\n",
    "    chosen1,                  # (i1, j1)\n",
    "    tokens_2d_step2,          # (L2, 2) coords AFTER merge #1, BEFORE merge #2\n",
    "    prob_matrix2,             # (L2, L2) softmax at step 2\n",
    "    chosen2,                  # (i2, j2)\n",
    "    figsize=(12, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes exactly two merge steps:\n",
    "    Merge #1 probability matrix + chosen pair\n",
    "    Merge #2 probability matrix + chosen pair\n",
    "    Final token 2-D scatter after the second merge.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    # ---- Helper to render each probability map ----\n",
    "    def render_prob(ax, P, chosen, title):\n",
    "        P = P.copy()\n",
    "        np.fill_diagonal(P, np.nan)              # mask diagonal\n",
    "        \n",
    "        im = ax.imshow(P, interpolation='nearest', cmap='viridis')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # highlight chosen pair\n",
    "        i, j = chosen\n",
    "        ax.scatter([j], [i], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "        ax.scatter([i], [j], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "\n",
    "        # nice grid\n",
    "        ax.set_xticks(np.arange(P.shape[1]) + 0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(P.shape[0]) + 0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linewidth=0.4)\n",
    "        ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "        # colorbar\n",
    "        fig.colorbar(im, ax=ax, fraction=0.10, pad=0.03)\n",
    "\n",
    "    # ---- Panel 1: merge #1 probability map ----\n",
    "    render_prob(axes[0], prob_matrix1, chosen1, \"Merge #1 Softmax\")\n",
    "\n",
    "    # ---- Panel 2: merge #2 probability map ----\n",
    "    render_prob(axes[1], prob_matrix2, chosen2, \"Merge #2 Softmax\")\n",
    "\n",
    "    # ---- Panel 3: final token positions after merge #2 ----\n",
    "    ax = axes[2]\n",
    "    ax.scatter(tokens_2d_step2[:,0], tokens_2d_step2[:,1],\n",
    "               s=40, color=\"black\")\n",
    "\n",
    "    # highlight merged token #2\n",
    "    mi2, mj2 = chosen2\n",
    "    merged_xy = tokens_2d_step2  # user passes correct coords after merge #2\n",
    "\n",
    "    # You can choose to mark the newly created token with a star if desired\n",
    "    # ax.scatter([merged_xy[-1,0]], [merged_xy[-1,1]],\n",
    "    #            s=200, marker=\"*\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "    ax.set_title(\"Tokens After Merge #2\")\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e904a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_merge_event_full(tokens_2d, prob_matrix, chosen_i, chosen_j,\n",
    "                     orig_traj, recon_traj, merged_token_2d=None,\n",
    "                     title_positions=\"Token positions\",\n",
    "                     title_matrix=\"Softmax merge probs\",\n",
    "                     title_recon=\"Original (blue), Recon (red)\",\n",
    "                     highlight_recon_idx=None):\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Convert to numpy\n",
    "    # ------------------------------------\n",
    "    if hasattr(tokens_2d, \"cpu\"):\n",
    "        tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "    if hasattr(prob_matrix, \"cpu\"):\n",
    "        prob_matrix = prob_matrix.detach().cpu().numpy()\n",
    "    if hasattr(orig_traj, \"cpu\"):\n",
    "        orig_traj = orig_traj.detach().cpu().numpy()\n",
    "    if hasattr(recon_traj, \"cpu\"):\n",
    "        recon_traj = recon_traj.detach().cpu().numpy()\n",
    "\n",
    "    # Create **3** subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    N = tokens_2d.shape[0]\n",
    "\n",
    "    # ========================================================\n",
    "    # 1 — Softmax matrix\n",
    "    # ========================================================\n",
    "    np.fill_diagonal(prob_matrix, np.nan)\n",
    "    ax = axes[0]\n",
    "    im = ax.imshow(prob_matrix, interpolation=\"nearest\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "    ax.set_title(title_matrix)\n",
    "    ax.set_xlabel(\"Token index\")\n",
    "    ax.set_ylabel(\"Token index\")\n",
    "\n",
    "    ax.set_xticks(range(N))\n",
    "    ax.set_yticks(range(N))\n",
    "\n",
    "    # highlight chosen merge pair\n",
    "    ax.scatter([chosen_j], [chosen_i], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "    ax.scatter([chosen_i], [chosen_j], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"black\", linewidth=0.2)\n",
    "\n",
    "    # ========================================================\n",
    "    # 2 — Token positions + merged token\n",
    "    # ========================================================\n",
    "    ax = axes[1]\n",
    "    ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "\n",
    "    for idx, (x,y) in enumerate(tokens_2d):\n",
    "        ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "    # highlight original pair\n",
    "    ax.scatter(\n",
    "        tokens_2d[[chosen_i, chosen_j],0],\n",
    "        tokens_2d[[chosen_i, chosen_j],1],\n",
    "        s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2\n",
    "    )\n",
    "\n",
    "    # merged token (star)\n",
    "    # if merged_token_2d is not None:\n",
    "    #     if hasattr(merged_token_2d, \"cpu\"):\n",
    "    #         merged_token_2d = merged_token_2d.detach().cpu().numpy()\n",
    "\n",
    "    #     ax.scatter(\n",
    "    #         [merged_token_2d[0]], [merged_token_2d[1]],\n",
    "    #         s=220, marker=\"*\", color=\"red\", linewidth=2,\n",
    "    #     )\n",
    "\n",
    "    ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"dim 1\")\n",
    "    ax.set_ylabel(\"dim 2\")\n",
    "\n",
    "    # ========================================================\n",
    "    # 3 — Original vs Reconstruction trajectory\n",
    "    # ========================================================\n",
    "    ax = axes[2]\n",
    "\n",
    "    \n",
    "\n",
    "    # draw original trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(orig_traj[:-1], orig_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"blue\", linewidth=1)\n",
    "\n",
    "    # draw reconstructed trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(recon_traj[:-1], recon_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"red\", linewidth=1)\n",
    "\n",
    "    if highlight_recon_idx is not None:\n",
    "        i, j = highlight_recon_idx\n",
    "        ax.scatter([recon_traj[i,0]], [recon_traj[i,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "        ax.scatter([recon_traj[j,0]], [recon_traj[j,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(title_recon)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d2aa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remap_softmax_to_buffer(prob_matrix, active_idx, full_N, removed_pairs):\n",
    "#     \"\"\"\n",
    "#     prob_matrix: (n_active, n_active) softmax matrix\n",
    "#     active_idx: indices in buffer corresponding to rows/cols of prob_matrix\n",
    "#     full_N: total buffer size BEFORE merge\n",
    "#     removed_pairs: indices that were merged and removed in that step\n",
    "#     \"\"\"\n",
    "#     out = np.full((full_N, full_N), np.nan)\n",
    "\n",
    "#     # Fill values for still-active tokens\n",
    "#     for i_local, i_global in enumerate(active_idx):\n",
    "#         for j_local, j_global in enumerate(active_idx):\n",
    "#             out[i_global, j_global] = prob_matrix[i_local, j_local]\n",
    "\n",
    "#     # Insert NaNs for removed tokens\n",
    "#     for dead in removed_pairs:\n",
    "#         out[dead, :] = np.nan\n",
    "#         out[:, dead] = np.nan\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def plot_2_merges(\n",
    "#         tokens_1, \n",
    "#         tokens_2, \n",
    "#         prob_matrix_1, \n",
    "#         prob_matrix_2,\n",
    "#         active_idx_1,\n",
    "#         active_idx_2,\n",
    "#         removed_1,\n",
    "#         removed_2,\n",
    "#         orig_traj_1,\n",
    "#         orig_traj_2,\n",
    "#         recon_traj_1,\n",
    "#         recon_traj_2,\n",
    "#         merged_token_1,\n",
    "#         merged_token_2\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     tokens_1, tokens_2: (n_active,2) 2D coordinates of tokens before each merge\n",
    "#     prob_matrix_1, prob_matrix_2: softmax matrices in ACTIVE index space\n",
    "#     active_idx_1, active_idx_2: active token -> buffer index mapping\n",
    "#     removed_1, removed_2: the pair removed at each step (global buffer indices)\n",
    "#     merged_token_1, merged_token_2: (2,) 2D coords of new merged token\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Determine full size\n",
    "#     full_N = max(active_idx_1.max(), active_idx_2.max()).item() + 1\n",
    "\n",
    "#     # --- Build full softmax matrices with NaNs inserted ---\n",
    "#     prob_full_1 = remap_softmax_to_buffer(prob_matrix_1, active_idx_1, full_N, removed_1)\n",
    "#     prob_full_2 = remap_softmax_to_buffer(prob_matrix_2, active_idx_2, full_N, removed_2)\n",
    "\n",
    "#     # --- Grid of 2 steps ---\n",
    "#     fig, axes = plt.subplots(2, 3, figsize=(17,10))\n",
    "\n",
    "#     # ============ STEP 1 ============\n",
    "#     _ = plot_merge_event_full(\n",
    "#         tokens_2d=tokens_1,\n",
    "#         prob_matrix=prob_full_1,\n",
    "#         chosen_i=removed_1[0], chosen_j=removed_1[1],\n",
    "#         orig_traj=orig_traj_1,\n",
    "#         recon_traj=recon_traj_1,\n",
    "#         merged_token_2d=merged_token_1,\n",
    "#         title_positions=\"Step 1 token positions\",\n",
    "#         title_matrix=\"Step 1 softmax (full buffer space)\",\n",
    "#         title_recon=\"Step 1 trajectories\",\n",
    "#     )\n",
    "\n",
    "#     # move result onto axes[0]\n",
    "#     fig.axes[-1].remove()   # remove auto-created fig from plot_merge_event_full\n",
    "#     for ax_from, ax_to in zip(plt.gcf().axes[-3:], axes[0]):\n",
    "#         fig.axes.remove(ax_from)\n",
    "#         fig.add_axes(ax_to)\n",
    "#         ax_to = ax_from\n",
    "\n",
    "#     # ============ STEP 2 ============\n",
    "#     _ = plot_merge_event_full(\n",
    "#         tokens_2d=tokens_2,\n",
    "#         prob_matrix=prob_full_2,\n",
    "#         chosen_i=removed_2[0], chosen_j=removed_2[1],\n",
    "#         orig_traj=orig_traj_2,\n",
    "#         recon_traj=recon_traj_2,\n",
    "#         merged_token_2d=merged_token_2,\n",
    "#         title_positions=\"Step 2 token positions\",\n",
    "#         title_matrix=\"Step 2 softmax (full buffer space)\",\n",
    "#         title_recon=\"Step 2 trajectories\",\n",
    "#     )\n",
    "\n",
    "#     # move onto axes[1]\n",
    "#     fig.axes[-1].remove()\n",
    "#     for ax_from, ax_to in zip(plt.gcf().axes[-3:], axes[1]):\n",
    "#         fig.axes.remove(ax_from)\n",
    "#         fig.add_axes(ax_to)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_merge_depth(curr_epoch, total_epochs, max_depth, power=2.0):\n",
    "    progress = curr_epoch / total_epochs\n",
    "    scaled = progress ** (1.0 / power)     # fast rise\n",
    "    depth = int(scaled * max_depth)        # quantize into buckets\n",
    "    return min(max(depth, 1), max_depth)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device, criterion, config, current_depth):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    policy = config.sampling_policy\n",
    "\n",
    "    for batch in val_loader:\n",
    "        raw_tokens = batch.to(device)\n",
    "        buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "        while buf.can_merge(current_depth):\n",
    "            active = buf.get_active_tokens()\n",
    "            B, N, D = active.shape\n",
    "            pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "            num_pairs = pair_idx.shape[0]\n",
    "\n",
    "            t1 = active[:, pair_idx[:, 0], :]\n",
    "            t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "            x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "            x_hat = model(x)\n",
    "\n",
    "            t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "            mse = nn.MSELoss(reduction=\"none\")\n",
    "            recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "            recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "            loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "            if policy == \"argmin\":\n",
    "                chosen = loss_per_pair.argmin(dim=1)\n",
    "            elif policy == \"softmax\":\n",
    "                probs = torch.softmax(-loss_per_pair / config.temperature, dim=1)\n",
    "                chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "            elif policy == \"uniform\":\n",
    "                chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown policy {policy}\")\n",
    "\n",
    "            local_t1_idx = pair_idx[chosen, 0]\n",
    "            local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "            chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "            chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "            chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "            # ---- Step Loss:\n",
    "            x_s = chosen_x \n",
    "            x_s_stop = chosen_x.detach()\n",
    "            x_s_hat = model(x_s) \n",
    "\n",
    "            t1_pred, t2_pred = torch.chunk(x_s_hat, 2, dim=-1)\n",
    "            t1_true, t2_true = torch.chunk(x_s_stop, 2, dim=-1)\n",
    "            mse = nn.MSELoss()\n",
    "            step_loss = nn.functional.mse_loss(t1_pred, t1_true) + nn.functional.mse_loss(t2_pred, t2_true)\n",
    "            # -----\n",
    "\n",
    "            merged_tokens = model.encode(chosen_x)\n",
    "\n",
    "            buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "        buffer = buf.buffer\n",
    "        merge_history = buf.get_merge_history()\n",
    "        active_mask = buf.get_active_mask()\n",
    "        n_original_tokens = raw_tokens.shape[1]    \n",
    "        unmerge_buf = TokenUnmergeBuffer(buffer=buffer, active_mask=active_mask, merges=merge_history, n_original=n_original_tokens) \n",
    "\n",
    "        while not unmerge_buf.is_done():\n",
    "            merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "            pred = model.decode(merged_token)\n",
    "            t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "            unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "        \n",
    "        reconstructed = unmerge_buf.get_original_tokens()\n",
    "\n",
    "        Lr = nn.functional.mse_loss(reconstructed, raw_tokens)        \n",
    "        Ls = step_loss * config.lambda_s\n",
    "        loss = Lr + Ls\n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(val_loader)\n",
    "\n",
    "    return total_loss, Lr, Ls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        config,\n",
    "        device,\n",
    "        checkpoint_path,\n",
    "        max_depth,\n",
    "        ):\n",
    "    \n",
    "    model.to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    b=0\n",
    "\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"random-walker\",\n",
    "        config=config,\n",
    "        name=config.model_name\n",
    "    )\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        orig_samples = None\n",
    "        recon_samples = None\n",
    "\n",
    "        capture_done = False\n",
    "        merge_viz_events = []\n",
    "        merge_figs = []\n",
    "        recon_fig = None\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            raw_tokens = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "\n",
    "            if orig_samples is None:\n",
    "                orig_samples = raw_tokens\n",
    "\n",
    "            buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "            # current_depth = get_merge_depth(epoch+1, config.epochs, config.max_depth)\n",
    "            if epoch < config.epochs // 2:\n",
    "                current_depth = 1\n",
    "            else:\n",
    "                current_depth = 2\n",
    "            \n",
    "\n",
    "            while buf.can_merge(current_depth):\n",
    "                active = buf.get_active_tokens()  # (B, N, D)\n",
    "                B, N, D = active.shape\n",
    "\n",
    "                pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "                num_pairs = pair_idx.shape[0]\n",
    "\n",
    "                t1 = active[:, pair_idx[:, 0], :]\n",
    "                t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "                x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "                x_hat = model(x)\n",
    "\n",
    "                t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "                mse = nn.MSELoss(reduction=\"none\")\n",
    "                recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "                recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "                loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "                policy = config.sampling_policy\n",
    "                if policy == \"argmin\":\n",
    "                    chosen = loss_per_pair.argmin(dim=1)\n",
    "                elif policy == \"uniform\":\n",
    "                    chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "                elif policy == \"softmax\":\n",
    "                    probs = torch.softmax(-loss_per_pair / config.temperature, dim=1)\n",
    "                    chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "\n",
    "                    if not capture_done:\n",
    "                        b = 0  # pick one sample to visualize\n",
    "\n",
    "                        chosen_i = pair_idx[chosen[b], 0].item()\n",
    "                        chosen_j = pair_idx[chosen[b], 1].item()\n",
    "\n",
    "                        token_prob_matrix = torch.zeros(N, N, device=device)\n",
    "                        for p in range(num_pairs):\n",
    "                            i = pair_idx[p, 0].item()\n",
    "                            j = pair_idx[p, 1].item()\n",
    "                            token_prob_matrix[i, j] = probs[b, p]\n",
    "                            token_prob_matrix[j, i] = probs[b, p]\n",
    "                        tokens_2d = active[b, :, :].detach().cpu()\n",
    "\n",
    "                        merge_viz_events.append({\n",
    "                            \"tokens_2d\": tokens_2d,\n",
    "                            \"prob_matrix\": token_prob_matrix.detach().cpu(),\n",
    "                            \"chosen_i\": chosen_i,\n",
    "                            \"chosen_j\": chosen_j,\n",
    "                            \"local_t1_idx\": None,    # fill later\n",
    "                            \"local_t2_idx\": None,\n",
    "                            \"merged_token_2d\": None  # fill after merge\n",
    "                        })\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown sampling policy: {policy}\")\n",
    "                \n",
    "                local_t1_idx = pair_idx[chosen, 0]\n",
    "                local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "                chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "                chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "                 \n",
    "                chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "                # ---- Step Loss:\n",
    "                x_s = chosen_x \n",
    "                x_s_stop = chosen_x.detach()\n",
    "                x_s_hat = model(x_s) \n",
    "\n",
    "                t1_pred, t2_pred = torch.chunk(x_s_hat, 2, dim=-1)\n",
    "                t1_true, t2_true = torch.chunk(x_s_stop, 2, dim=-1)\n",
    "                mse = nn.MSELoss()\n",
    "                step_loss = mse(t1_pred, t1_true) + mse(t2_pred, t2_true)\n",
    "                # -----\n",
    "\n",
    "                merged_tokens = model.encode(chosen_x)\n",
    "                buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "                if len(merge_viz_events) <= 2:   # store only first 2 merges\n",
    "                    \n",
    "                    merge_viz_events[-1][\"local_t1_idx\"] = local_t1_idx[b].item()\n",
    "                    merge_viz_events[-1][\"local_t2_idx\"] = local_t2_idx[b].item()\n",
    "                    merge_viz_events[-1][\"merged_token_2d\"] = merged_tokens[b, :2].detach().cpu()\n",
    "\n",
    "            buffer = buf.buffer\n",
    "            merge_history = buf.get_merge_history()\n",
    "            active_mask = buf.get_active_mask()\n",
    "            n_original_tokens = raw_tokens.shape[1]\n",
    "\n",
    "            unmerge_buf = TokenUnmergeBuffer(buffer=buffer,\n",
    "                                             active_mask=active_mask,\n",
    "                                             merges=merge_history,\n",
    "                                             n_original=n_original_tokens)\n",
    "\n",
    "            \n",
    "            while not unmerge_buf.is_done():\n",
    "                merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "                pred = model.decode(merged_token)\n",
    "                t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "                unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "            reconstructed = unmerge_buf.get_original_tokens()\n",
    "            \n",
    "            if recon_fig is None:\n",
    "                recon_fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "   \n",
    "\n",
    "                for i in range(5):\n",
    "                    sample1 = reconstructed[i].detach().cpu()\n",
    "                    sample2 = raw_tokens[i].detach().cpu()\n",
    "\n",
    "                    axes[i].scatter(sample1[:, 0], sample1[:, 1], color='blue', alpha=0.3)\n",
    "                    axes[i].scatter(sample2[:, 0], sample2[:, 1], color='red', alpha=0.7, s=10)\n",
    "                    \n",
    "                    # axes[i].set_title(f\"{sample1.shape}\")\n",
    "                    axes[i].set_xlabel(\"x\")\n",
    "                    axes[i].set_ylabel(\"y\")\n",
    "\n",
    "\n",
    "            if not capture_done:\n",
    "                if len(merge_viz_events) >= 1:\n",
    "                    orig_traj = raw_tokens[b, :, :2].detach().cpu()\n",
    "                    recon_traj = reconstructed[b, :, :2].detach().cpu()\n",
    "\n",
    "                    # print(orig_traj-recon_traj)\n",
    "\n",
    "                    # --- For each merge event we stored ---\n",
    "                    for k, event in enumerate(merge_viz_events[:2]):\n",
    "                        fig = plot_merge_event_full(\n",
    "                            tokens_2d=event[\"tokens_2d\"],\n",
    "                            prob_matrix=event[\"prob_matrix\"],\n",
    "                            chosen_i=event[\"chosen_i\"],\n",
    "                            chosen_j=event[\"chosen_j\"],\n",
    "                            orig_traj=orig_traj,\n",
    "                            recon_traj=recon_traj,\n",
    "                            merged_token_2d=event[\"merged_token_2d\"],\n",
    "                            highlight_recon_idx=(event[\"local_t1_idx\"], event[\"local_t2_idx\"]),\n",
    "                            title_matrix=f\"Softmax merge probs (step {k+1})\",\n",
    "                            title_positions=f\"Token positions (step {k+1})\"\n",
    "                        )\n",
    "                        merge_figs.append(fig)\n",
    "                        plt.close(fig)\n",
    "\n",
    "                capture_done = True\n",
    "\n",
    "\n",
    "            Lr = criterion(reconstructed, raw_tokens)\n",
    "            Ls = step_loss * config.lambda_s\n",
    "            loss = Lr + Ls\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        val_loss, val_Lr, val_Ls = evaluate(model, val_loader, device, criterion, config, current_depth)\n",
    "\n",
    "                \n",
    "        if checkpoint_path and val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        log_dict = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_e2e_recon_loss\": Lr,\n",
    "        \"train_step_loss\": Ls,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_e2e_recon_loss\": val_Lr,\n",
    "        \"val_step_loss\": val_Ls,\n",
    "        \"epoch\": epoch,\n",
    "        \"merge_depth\": current_depth,\n",
    "        \"merge_event_step_1\": wandb.Image(merge_figs[0]),\n",
    "        \"recon_fig\": wandb.Image(recon_fig),\n",
    "        }\n",
    "        if len(merge_figs) > 1:\n",
    "            log_dict[\"merge_event_step_2\"] = wandb.Image(merge_figs[1])\n",
    "\n",
    "        plt.close(recon_fig)\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "        \n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d359915",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef8e588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fabian/Uni/htm/wandb/run-20251205_130101-l06ft5ce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fabianhahn/random-walker/runs/l06ft5ce' target=\"_blank\">softmax-0.5-lr-0.0001-merges-2</a></strong> to <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fabianhahn/random-walker/runs/l06ft5ce' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker/runs/l06ft5ce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>merge_depth</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>train_e2e_recon_loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▁▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step_loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_e2e_recon_loss</td><td>█▆▄▄▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_step_loss</td><td>█▆▅▅▅▄▄▄▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>merge_depth</td><td>2</td></tr><tr><td>train_e2e_recon_loss</td><td>0.01797</td></tr><tr><td>train_loss</td><td>0.49966</td></tr><tr><td>train_step_loss</td><td>0.34234</td></tr><tr><td>val_e2e_recon_loss</td><td>0.05112</td></tr><tr><td>val_loss</td><td>0.84947</td></tr><tr><td>val_step_loss</td><td>0.67548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">softmax-0.5-lr-0.0001-merges-2</strong> at: <a href='https://wandb.ai/fabianhahn/random-walker/runs/l06ft5ce' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker/runs/l06ft5ce</a><br> View project at: <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker</a><br>Synced 4 W&B file(s), 125 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251205_130101-l06ft5ce/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_dim = 2\n",
    "latent_dim = 2\n",
    "hidden_dim = 128\n",
    "merges = 2\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    epochs=50,\n",
    "    learning_rate=1e-4,\n",
    "    sampling_policy=\"softmax\",\n",
    "    batch_size=128,\n",
    "    device=device,\n",
    "    model_name=f\"softmax-0.5-lr-{1e-4}-merges-{merges}\",\n",
    "    max_depth=merges,\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    temperature=0.5,\n",
    "    lambda_s=5,\n",
    "    latent_dim=latent_dim,\n",
    ")\n",
    "\n",
    "model = AE_no_lift(\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    latent_dim=latent_dim\n",
    "    ).to(device)\n",
    "\n",
    "train(model, train_loader, val_loader, config, device, checkpoint_path=f\"./checkpoints/{config.model_name}.pth\", max_depth=merges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
