{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de81cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from util import TokenMergeBuffer, TokenUnmergeBuffer, EarlyStopper\n",
    "from models import AE_no_lift\n",
    "from toy_data.environments import RandomWalker\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e850c1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a51c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "walker = RandomWalker(\n",
    "    n=1000, \n",
    "    length=10, \n",
    "    dim=2, \n",
    "    step_scale=0.1, \n",
    "    init=\"normal\", \n",
    "    drift=\"centre\").generate()\n",
    "\n",
    "dataset = torch.tensor(walker.data, dtype=torch.float32)\n",
    "\n",
    "train_pct = 0.8\n",
    "train_size = int(train_pct * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a7910",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ecb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_merge_event(tokens_2d, prob_matrix, chosen_i, chosen_j, orig_traj, recon_traj, merged_token_2d=None,\n",
    "#                      title_positions=\"Token positions\",\n",
    "#                      title_matrix=\"Softmax merge probs\",\n",
    "#                      title_recon=\"Original (blue), Recon (red)\"):\n",
    "\n",
    "#     # ---------------- existing code ----------------\n",
    "#     if hasattr(tokens_2d, \"cpu\"):\n",
    "#         tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "#     if hasattr(prob_matrix, \"cpu\"):\n",
    "#         prob_matrix = prob_matrix.detach().cpu().numpy()\n",
    "\n",
    "#     N = tokens_2d.shape[0]\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # 2 — Softmax matrix\n",
    "#     # --------------------------------------------------------\n",
    "#     ax = axes[0]\n",
    "#     im = ax.imshow(prob_matrix, interpolation=\"nearest\")\n",
    "#     fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "#     ax.set_title(title_matrix)\n",
    "#     ax.set_xlabel(\"Token index\")\n",
    "#     ax.set_ylabel(\"Token index\")\n",
    "\n",
    "#     ax.set_xticks(range(N))\n",
    "#     ax.set_yticks(range(N))\n",
    "\n",
    "#     ax.scatter([chosen_j], [chosen_i], s=250, facecolor=\"none\",\n",
    "#                edgecolor=\"red\", linewidth=2)\n",
    "#     ax.scatter([chosen_i], [chosen_j], s=250, facecolor=\"none\",\n",
    "#                edgecolor=\"red\", linewidth=2)\n",
    "\n",
    "#     ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "#     ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "#     ax.grid(which=\"minor\", color=\"black\", linewidth=0.2)\n",
    "\n",
    "#         # ================= LEFT PLOT =====================\n",
    "#     ax = axes[1]\n",
    "#     ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "\n",
    "#     for idx, (x,y) in enumerate(tokens_2d):\n",
    "#         ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "#     # highlight original merged tokens\n",
    "#     ax.scatter(\n",
    "#         tokens_2d[[chosen_i, chosen_j],0],\n",
    "#         tokens_2d[[chosen_i, chosen_j],1],\n",
    "#         s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2,\n",
    "#         label=\"Original merge pair\"\n",
    "#     )\n",
    "\n",
    "#     # --- NEW: plot the merged token ---\n",
    "#     if merged_token_2d is not None:\n",
    "#         if hasattr(merged_token_2d, \"cpu\"):\n",
    "#             merged_token_2d = merged_token_2d.detach().cpu().numpy()\n",
    "\n",
    "#         ax.scatter(\n",
    "#             [merged_token_2d[0]], [merged_token_2d[1]],\n",
    "#             s=220, marker=\"*\", color=\"red\", linewidth=2,\n",
    "#             label=\"Merged token\"\n",
    "#         )\n",
    "\n",
    "#     ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.set_xlabel(\"dim 1\")\n",
    "#     ax.set_ylabel(\"dim 2\")\n",
    "#     # ax.legend()\n",
    "#     # # --------------------------------------------------------\n",
    "#     # # 1 — Token positions\n",
    "#     # # --------------------------------------------------------\n",
    "#     # ax = axes[1]\n",
    "#     # ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "#     # for idx, (x,y) in enumerate(tokens_2d):\n",
    "#     #     ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "#     # ax.scatter(tokens_2d[[chosen_i, chosen_j],0],\n",
    "#     #            tokens_2d[[chosen_i, chosen_j],1],\n",
    "#     #            s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "#     # ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "#     # ax.set_xlabel(\"dim 1\")\n",
    "#     # ax.set_ylabel(\"dim 2\")\n",
    "#     # ax.set_aspect(\"equal\")\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # 3 — Original vs Reconstruction trajectory\n",
    "#     # --------------------------------------------------------\n",
    "#     ax = axes[2]\n",
    "\n",
    "#     # draw lines\n",
    "#     for (x0, y0), (x1, y1) in zip(orig_traj[:-1], orig_traj[1:]):\n",
    "#         ax.plot([x0, x1], [y0, y1], color=\"blue\", linewidth=1)\n",
    "\n",
    "#     for (x0, y0), (x1, y1) in zip(recon_traj[:-1], recon_traj[1:]):\n",
    "#         ax.plot([x0, x1], [y0, y1], color=\"red\", linewidth=1)\n",
    "\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.set_title(title_recon)\n",
    "#     ax.set_xlabel(\"x\")\n",
    "#     ax.set_ylabel(\"y\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e7c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_merge_event_full(tokens_2d, prob_matrix, chosen_i, chosen_j,\n",
    "                     orig_traj, recon_traj, merged_token_2d=None,\n",
    "                     title_positions=\"Token positions\",\n",
    "                     title_matrix=\"Softmax merge probs\",\n",
    "                     title_recon=\"Original (blue), Recon (red)\",\n",
    "                     highlight_recon_idx=None):\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Convert to numpy\n",
    "    # ------------------------------------\n",
    "    if hasattr(tokens_2d, \"cpu\"):\n",
    "        tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "    if hasattr(prob_matrix, \"cpu\"):\n",
    "        prob_matrix = prob_matrix.detach().cpu().numpy()\n",
    "    if hasattr(orig_traj, \"cpu\"):\n",
    "        orig_traj = orig_traj.detach().cpu().numpy()\n",
    "    if hasattr(recon_traj, \"cpu\"):\n",
    "        recon_traj = recon_traj.detach().cpu().numpy()\n",
    "\n",
    "    # Create **3** subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    N = tokens_2d.shape[0]\n",
    "\n",
    "    # ========================================================\n",
    "    # 1 — Softmax matrix\n",
    "    # ========================================================\n",
    "    np.fill_diagonal(prob_matrix, np.nan)\n",
    "    ax = axes[0]\n",
    "    im = ax.imshow(prob_matrix, interpolation=\"nearest\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "    ax.set_title(title_matrix)\n",
    "    ax.set_xlabel(\"Token index\")\n",
    "    ax.set_ylabel(\"Token index\")\n",
    "\n",
    "    ax.set_xticks(range(N))\n",
    "    ax.set_yticks(range(N))\n",
    "\n",
    "    # highlight chosen merge pair\n",
    "    ax.scatter([chosen_j], [chosen_i], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "    ax.scatter([chosen_i], [chosen_j], s=250, facecolor=\"none\",\n",
    "               edgecolor=\"red\", linewidth=2)\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"black\", linewidth=0.2)\n",
    "\n",
    "    # ========================================================\n",
    "    # 2 — Token positions + merged token\n",
    "    # ========================================================\n",
    "    ax = axes[1]\n",
    "    ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "\n",
    "    for idx, (x,y) in enumerate(tokens_2d):\n",
    "        ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "    # highlight original pair\n",
    "    ax.scatter(\n",
    "        tokens_2d[[chosen_i, chosen_j],0],\n",
    "        tokens_2d[[chosen_i, chosen_j],1],\n",
    "        s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2\n",
    "    )\n",
    "\n",
    "    # merged token (star)\n",
    "    if merged_token_2d is not None:\n",
    "        if hasattr(merged_token_2d, \"cpu\"):\n",
    "            merged_token_2d = merged_token_2d.detach().cpu().numpy()\n",
    "\n",
    "        ax.scatter(\n",
    "            [merged_token_2d[0]], [merged_token_2d[1]],\n",
    "            s=220, marker=\"*\", color=\"red\", linewidth=2,\n",
    "        )\n",
    "\n",
    "    ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"dim 1\")\n",
    "    ax.set_ylabel(\"dim 2\")\n",
    "\n",
    "    # ========================================================\n",
    "    # 3 — Original vs Reconstruction trajectory\n",
    "    # ========================================================\n",
    "    ax = axes[2]\n",
    "\n",
    "    \n",
    "\n",
    "    # draw original trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(orig_traj[:-1], orig_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"blue\", linewidth=1)\n",
    "\n",
    "    # draw reconstructed trajectory\n",
    "    for (x0, y0), (x1, y1) in zip(recon_traj[:-1], recon_traj[1:]):\n",
    "        ax.plot([x0, x1], [y0, y1], color=\"red\", linewidth=1)\n",
    "\n",
    "    if highlight_recon_idx is not None:\n",
    "        i, j = highlight_recon_idx\n",
    "        ax.scatter([recon_traj[i,0]], [recon_traj[i,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "        ax.scatter([recon_traj[j,0]], [recon_traj[j,1]],\n",
    "                s=50, marker=\"*\", color=\"red\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(title_recon)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_two_merge_event(\n",
    "    tokens_2d_step1,          # (L1, 2) coords BEFORE merge #1\n",
    "    prob_matrix1,             # (L1, L1) softmax AFTER masking/softmax\n",
    "    chosen1,                  # (i1, j1)\n",
    "    tokens_2d_step2,          # (L2, 2) coords AFTER merge #1, BEFORE merge #2\n",
    "    prob_matrix2,             # (L2, L2) softmax at step 2\n",
    "    chosen2,                  # (i2, j2)\n",
    "    figsize=(12, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes exactly two merge steps:\n",
    "    Merge #1 probability matrix + chosen pair\n",
    "    Merge #2 probability matrix + chosen pair\n",
    "    Final token 2-D scatter after the second merge.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    # ---- Helper to render each probability map ----\n",
    "    def render_prob(ax, P, chosen, title):\n",
    "        P = P.copy()\n",
    "        np.fill_diagonal(P, np.nan)              # mask diagonal\n",
    "        \n",
    "        im = ax.imshow(P, interpolation='nearest', cmap='viridis')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # highlight chosen pair\n",
    "        i, j = chosen\n",
    "        ax.scatter([j], [i], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "        ax.scatter([i], [j], s=80, edgecolor=\"red\", facecolor=\"none\", linewidth=1.5)\n",
    "\n",
    "        # nice grid\n",
    "        ax.set_xticks(np.arange(P.shape[1]) + 0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(P.shape[0]) + 0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linewidth=0.4)\n",
    "        ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "        # colorbar\n",
    "        fig.colorbar(im, ax=ax, fraction=0.10, pad=0.03)\n",
    "\n",
    "    # ---- Panel 1: merge #1 probability map ----\n",
    "    render_prob(axes[0], prob_matrix1, chosen1, \"Merge #1 Softmax\")\n",
    "\n",
    "    # ---- Panel 2: merge #2 probability map ----\n",
    "    render_prob(axes[1], prob_matrix2, chosen2, \"Merge #2 Softmax\")\n",
    "\n",
    "    # ---- Panel 3: final token positions after merge #2 ----\n",
    "    ax = axes[2]\n",
    "    ax.scatter(tokens_2d_step2[:,0], tokens_2d_step2[:,1],\n",
    "               s=40, color=\"black\")\n",
    "\n",
    "    # highlight merged token #2\n",
    "    mi2, mj2 = chosen2\n",
    "    merged_xy = tokens_2d_step2  # user passes correct coords after merge #2\n",
    "\n",
    "    # You can choose to mark the newly created token with a star if desired\n",
    "    # ax.scatter([merged_xy[-1,0]], [merged_xy[-1,1]],\n",
    "    #            s=200, marker=\"*\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "    ax.set_title(\"Tokens After Merge #2\")\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8319ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_depth(curr_epoch, total_epochs, max_depth, power=2.0):\n",
    "    progress = curr_epoch / total_epochs\n",
    "    scaled = progress ** (1.0 / power)     # fast rise\n",
    "    depth = int(scaled * max_depth)        # quantize into buckets\n",
    "    return min(max(depth, 1), max_depth)\n",
    "\n",
    "def plot_token_matrix(matrix, title=\"Token Merge Probabilities\"):\n",
    "    if hasattr(matrix, \"cpu\"):\n",
    "        matrix = matrix.cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    im = ax.imshow(matrix, interpolation=\"nearest\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Token index\")\n",
    "    ax.set_ylabel(\"Token index\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    N = matrix.shape[0]\n",
    "    ax.set_xticks(range(N))\n",
    "    ax.set_yticks(range(N))\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_token_positions(tokens_2d, chosen_i, chosen_j, title=\"2D Token Embeddings\"):\n",
    "    if hasattr(tokens_2d, \"cpu\"):\n",
    "        tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "\n",
    "    ax.scatter(tokens_2d[:,0], tokens_2d[:,1])\n",
    "\n",
    "    for idx, (x,y) in enumerate(tokens_2d):\n",
    "        ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "    ax.scatter(tokens_2d[[chosen_i, chosen_j],0],\n",
    "               tokens_2d[[chosen_i, chosen_j],1],\n",
    "               s=150, edgecolor=\"black\", linewidth=2)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"dim 1\")\n",
    "    ax.set_ylabel(\"dim 2\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualise(orig, recon, show=False):\n",
    "\n",
    "    if isinstance(orig, torch.Tensor):\n",
    "        orig = orig.detach().cpu().numpy()\n",
    "    if isinstance(recon, torch.Tensor):\n",
    "        recon = recon.detach().cpu().numpy()\n",
    "\n",
    "    def plot_trajectory(traj, ax, color=\"blue\", label=None, linewidth=1, linestyle=\"solid\"):\n",
    "        for (x0, y0), (x1, y1) in zip(traj[:-1], traj[1:]):\n",
    "            ax.plot([x0, x1], [y0, y1], color=color, linewidth=1, linestyle=linestyle)\n",
    "\n",
    "        if label:\n",
    "            ax.plot([], [], color=color, label=label)\n",
    "\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        return ax\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    plot_trajectory(orig, ax=ax, color=\"blue\", label=\"Original\", linewidth=2)\n",
    "    plot_trajectory(recon, ax=ax, color=\"red\", label=\"Reconstruction\", linestyle=\"solid\")\n",
    "\n",
    "    # ax.set_title(\"\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "\n",
    "    # ax.set_xlim(-2, 2)\n",
    "    # ax.set_ylim(-2, 2)\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    if show: \n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "    \n",
    "def visualise_multiple(orig_list, recon_list, show=False):\n",
    "    \"\"\"\n",
    "    orig_list, recon_list: lists of trajectories (numpy arrays or torch tensors)\n",
    "    \"\"\"\n",
    "    n = len(orig_list)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(6 * n, 6))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (orig, recon) in enumerate(zip(orig_list, recon_list)):\n",
    "        if isinstance(orig, torch.Tensor):\n",
    "            orig = orig.detach().cpu().numpy()\n",
    "        if isinstance(recon, torch.Tensor):\n",
    "            recon = recon.detach().cpu().numpy()\n",
    "\n",
    "        ax = axes[i]\n",
    "\n",
    "        # plot original\n",
    "        line_orig, = ax.plot([], [], color=\"blue\", linewidth=1)\n",
    "        for (x0, y0), (x1, y1) in zip(orig[:-1], orig[1:]):\n",
    "            ax.plot([x0, x1], [y0, y1], color=\"blue\", linewidth=1)\n",
    "        # plot reconstruction\n",
    "        line_recon, = ax.plot([], [], color=\"red\", linewidth=1)\n",
    "        for (x0, y0), (x1, y1) in zip(recon[:-1], recon[1:]):\n",
    "            ax.plot([x0, x1], [y0, y1], color=\"red\", linewidth=1)\n",
    "\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.set_title(f\"Sample {i+1}\")\n",
    "\n",
    "        if i == 0:\n",
    "            legend_lines = [line_orig, line_recon]\n",
    "\n",
    "    fig.legend(legend_lines, [\"Original\", \"Reconstruction\"], loc=\"upper right\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "\n",
    "\n",
    "def visualise_merge_progress(orig, merge_snapshots, show=False):\n",
    "    \"\"\"\n",
    "    Visualize step-by-step merging of tokens.\n",
    "    \n",
    "    Parameters:\n",
    "    - orig: original trajectory (N, 2)\n",
    "    - merge_snapshots: list of intermediate merged tokens (arrays of shape M,2)\n",
    "    - show: whether to plt.show() or just return the figure\n",
    "    \"\"\"\n",
    "    if isinstance(orig, torch.Tensor):\n",
    "        orig = orig.detach().cpu().numpy()\n",
    "    merge_snapshots = [s.detach().cpu().numpy() if isinstance(s, torch.Tensor) else s for s in merge_snapshots]\n",
    "\n",
    "    n_steps = len(merge_snapshots)\n",
    "    fig, axes = plt.subplots(1, n_steps + 1, figsize=(5 * (n_steps + 1), 5))\n",
    "\n",
    "    if n_steps == 0:\n",
    "        axes = [axes]\n",
    "    if n_steps == 1:\n",
    "        axes = [axes[0], axes[1]]\n",
    "\n",
    "    # Plot original on first subplot\n",
    "    ax = axes[0]\n",
    "    ax.scatter(orig[:,0], orig[:,1], color='blue', label='Original', s=30)\n",
    "    ax.set_title(\"Original\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Plot merged snapshots step by step\n",
    "    for i, merged in enumerate(merge_snapshots):\n",
    "        ax = axes[i+1]\n",
    "        ax.scatter(orig[:,0], orig[:,1], color='blue', alpha=0.2, label='Original', s=20)\n",
    "        ax.scatter(merged[:,0], merged[:,1], color='red', label=f'Merged step {i+1}', s=50)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Merge step {i+1}\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "\n",
    "\n",
    "# def plot_merge_event(tokens_2d, prob_matrix, chosen_i, chosen_j, \n",
    "#                      title_positions=\"Token positions\", \n",
    "#                      title_matrix=\"Softmax merge probs\"):\n",
    "#     \"\"\"\n",
    "#     tokens_2d: (N,2) numpy or tensor\n",
    "#     prob_matrix: (N,N) numpy or tensor\n",
    "#     chosen_i, chosen_j: merged indices\n",
    "#     \"\"\"\n",
    "#     # tensor → numpy\n",
    "#     if hasattr(tokens_2d, \"cpu\"):\n",
    "#         tokens_2d = tokens_2d.detach().cpu().numpy()\n",
    "#     if hasattr(prob_matrix, \"cpu\"):\n",
    "#         prob_matrix = prob_matrix.detach().cpu().numpy()\n",
    "\n",
    "#     N = tokens_2d.shape[0]\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # LEFT PLOT — Token positions + highlight merged pair\n",
    "#     # --------------------------------------------------------\n",
    "#     ax = axes[0]\n",
    "#     ax.scatter(tokens_2d[:,0], tokens_2d[:,1], s=40)\n",
    "\n",
    "#     for idx, (x,y) in enumerate(tokens_2d):\n",
    "#         ax.text(x+0.02, y+0.02, str(idx))\n",
    "\n",
    "#     # highlight merged tokens\n",
    "#     ax.scatter(tokens_2d[[chosen_i, chosen_j],0],\n",
    "#                tokens_2d[[chosen_i, chosen_j],1],\n",
    "#                s=200, edgecolor=\"black\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "#     ax.set_title(f\"{title_positions}\\nMerged: ({chosen_i}, {chosen_j})\")\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.set_xlabel(\"dim 1\")\n",
    "#     ax.set_ylabel(\"dim 2\")\n",
    "\n",
    "\n",
    "#     # --------------------------------------------------------\n",
    "#     # RIGHT PLOT — Softmax probability matrix + highlight pair\n",
    "#     # --------------------------------------------------------\n",
    "#     ax = axes[1]\n",
    "#     im = ax.imshow(prob_matrix, interpolation=\"nearest\")\n",
    "#     fig.colorbar(im, ax=ax)\n",
    "\n",
    "#     ax.set_title(title_matrix)\n",
    "#     ax.set_xlabel(\"Token index\")\n",
    "#     ax.set_ylabel(\"Token index\")\n",
    "\n",
    "#     ax.set_xticks(range(N))\n",
    "#     ax.set_yticks(range(N))\n",
    "\n",
    "#     # highlight chosen merge in matrix\n",
    "#     ax.scatter([chosen_j], [chosen_i], s=250, facecolor=\"none\",\n",
    "#                edgecolor=\"red\", linewidth=2)\n",
    "#     ax.scatter([chosen_i], [chosen_j], s=250, facecolor=\"none\",\n",
    "#                edgecolor=\"red\", linewidth=2)\n",
    "\n",
    "#     # minor grid\n",
    "#     ax.set_xticks(np.arange(-.5, N, 1), minor=True)\n",
    "#     ax.set_yticks(np.arange(-.5, N, 1), minor=True)\n",
    "#     ax.grid(which=\"minor\", color=\"black\", linewidth=0.2)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device, policy, current_depth, criterion, temperature=1):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        raw_tokens = batch.to(device)\n",
    "        buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "        while buf.can_merge(current_depth):\n",
    "            active = buf.get_active_tokens()\n",
    "            B, N, D = active.shape\n",
    "            pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "            num_pairs = pair_idx.shape[0]\n",
    "\n",
    "            t1 = active[:, pair_idx[:, 0], :]\n",
    "            t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "            t1 = t1.detach()\n",
    "            t2 = t2.detach()\n",
    "\n",
    "            x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "            x_hat = model(x)\n",
    "\n",
    "            t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "            mse = nn.MSELoss(reduction=\"none\")\n",
    "            recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "            recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "            loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "            if policy == \"argmin\":\n",
    "                chosen = loss_per_pair.argmin(dim=1)\n",
    "            elif policy == \"softmax\":\n",
    "                probs = torch.softmax(-loss_per_pair / temperature, dim=1)\n",
    "                chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "            elif policy == \"uniform\":\n",
    "                chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown policy {policy}\")\n",
    "\n",
    "            local_t1_idx = pair_idx[chosen, 0]\n",
    "            local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "            chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "            chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "            chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "            merged_tokens = model.encode(chosen_x)\n",
    "\n",
    "            buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "        buffer = buf.buffer\n",
    "        merge_history = buf.get_merge_history()\n",
    "        active_mask = buf.get_active_mask()\n",
    "        n_original_tokens = raw_tokens.shape[1]    \n",
    "        unmerge_buf = TokenUnmergeBuffer(buffer=buffer, active_mask=active_mask, merges=merge_history, n_original=n_original_tokens) \n",
    "\n",
    "        while not unmerge_buf.is_done():\n",
    "            merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "            pred = model.decode(merged_token)\n",
    "            t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "            unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "        \n",
    "        reconstructed = unmerge_buf.get_original_tokens()\n",
    "\n",
    "        loss = criterion(reconstructed, raw_tokens)\n",
    "\n",
    "        total_loss += loss.item() # TODO: eventuell ohne .item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        config,\n",
    "        device,\n",
    "        checkpoint_path,\n",
    "        max_depth,\n",
    "        ):\n",
    "    \n",
    "    model.to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimiser, mode='min', factor=0.8, patience=15, verbose=True, min_lr=1e-6\n",
    "    # )    \n",
    "    stopper = EarlyStopper(patience=10, min_delta=1e-4)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"random-walker\",\n",
    "        config=config,\n",
    "        name=config.model_name\n",
    "    )\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        orig_samples = None\n",
    "        recon_samples = None\n",
    "\n",
    "        capture_done = False\n",
    "\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            raw_tokens = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "\n",
    "            if orig_samples is None:\n",
    "                orig_samples = raw_tokens\n",
    "\n",
    "            buf = TokenMergeBuffer(raw_tokens)\n",
    "\n",
    "            current_depth = get_merge_depth(epoch+1, config.epochs, config.max_depth)\n",
    "            # current_depth = max_depth\n",
    "            \n",
    "            merge_snapshots_per_sample = [[] for _ in range(5)] \n",
    "\n",
    "            while buf.can_merge(current_depth):\n",
    "                active = buf.get_active_tokens()  # (B, N, D)\n",
    "                B, N, D = active.shape\n",
    "\n",
    "                for i in range(5):\n",
    "                    merge_snapshots_per_sample[i].append(active[i, :, :2].detach().cpu().numpy())\n",
    "\n",
    "                pair_idx = torch.combinations(torch.arange(N, device=device))\n",
    "                num_pairs = pair_idx.shape[0]\n",
    "\n",
    "                t1 = active[:, pair_idx[:, 0], :]\n",
    "                t2 = active[:, pair_idx[:, 1], :]\n",
    "\n",
    "                t1 = t1.detach()\n",
    "                t2 = t2.detach()\n",
    "\n",
    "                x = torch.cat([t1, t2], dim=-1)\n",
    "\n",
    "                x_hat = model(x)\n",
    "\n",
    "                t1_hat, t2_hat = torch.chunk(x_hat, 2, dim=-1)                    \n",
    "\n",
    "                mse = nn.MSELoss(reduction=\"none\")\n",
    "                recon_t1 = mse(t1, t1_hat).mean(dim=-1)\n",
    "                recon_t2 = mse(t2, t2_hat).mean(dim=-1)\n",
    "                loss_per_pair = recon_t1 + recon_t2\n",
    "\n",
    "                policy = config.sampling_policy\n",
    "                if policy == \"argmin\":\n",
    "                    chosen = loss_per_pair.argmin(dim=1)\n",
    "                elif policy == \"uniform\":\n",
    "                    chosen = torch.randint(0, num_pairs, (B,), device=device)\n",
    "                elif policy == \"softmax\":\n",
    "                    probs = torch.softmax(-loss_per_pair / config.temperature, dim=1)\n",
    "                    chosen = torch.multinomial(probs, 1).squeeze(1)\n",
    "\n",
    "                   # --- NEW: Collect visualisation for the first sample in batch ---\n",
    "                    b = 0  # pick one sample to visualize\n",
    "\n",
    "                    # chosen pair for this step (for sample b)\n",
    "                    chosen_i = pair_idx[chosen[b], 0].item()\n",
    "                    chosen_j = pair_idx[chosen[b], 1].item()\n",
    "\n",
    "                    # --- Token correlation matrix for this step ---\n",
    "                    token_prob_matrix = torch.zeros(N, N, device=device)\n",
    "\n",
    "                    for p in range(num_pairs):\n",
    "                        i = pair_idx[p, 0].item()\n",
    "                        j = pair_idx[p, 1].item()\n",
    "                        token_prob_matrix[i, j] = probs[b, p]\n",
    "                        token_prob_matrix[j, i] = probs[b, p]\n",
    "\n",
    "                    # if \"token_prob_matrix_frames\" not in locals():\n",
    "                    #     token_prob_matrix_frames = []\n",
    "                    # token_prob_matrix_frames.append(token_prob_matrix.detach().cpu())\n",
    "\n",
    "                    # --- 2D token visualisation (use first 2 dims) ---\n",
    "                    tokens_2d = active[b, :, :2]\n",
    "\n",
    "                    # if \"token_position_frames\" not in locals():\n",
    "                    #     token_position_frames = []\n",
    "                    # token_position_frames.append((tokens_2d.detach().cpu(),\n",
    "                    #                             chosen_i,\n",
    "                    #                             chosen_j))\n",
    "                    # ------------------------------------------------------------\n",
    "                    # if not capture_done:\n",
    "                    #     fig_merge = plot_merge_event(tokens_2d, token_prob_matrix, chosen_i, chosen_j)\n",
    "                    #     wandb.log({\"merge_event\": wandb.Image(fig_merge)})\n",
    "                    #     plt.close(fig_merge)\n",
    "                    #     capture_done = True\n",
    "\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown sampling policy: {policy}\")\n",
    "                \n",
    "                local_t1_idx = pair_idx[chosen, 0]\n",
    "                local_t2_idx = pair_idx[chosen, 1]\n",
    "\n",
    "                chosen_t1 = active[torch.arange(B), local_t1_idx, :]\n",
    "                chosen_t2 = active[torch.arange(B), local_t2_idx, :]\n",
    "\n",
    "                 \n",
    "                chosen_x = torch.cat([chosen_t1, chosen_t2], dim=-1)\n",
    "\n",
    "                merged_tokens = model.encode(chosen_x)\n",
    "                buf.merge_batch(local_t1_idx, local_t2_idx, merged_tokens)\n",
    "\n",
    "                merged_token_2d = merged_tokens[b, :2].detach().cpu() # part of viz \n",
    "\n",
    "\n",
    "            buffer = buf.buffer\n",
    "            merge_history = buf.get_merge_history()\n",
    "            active_mask = buf.get_active_mask()\n",
    "            n_original_tokens = raw_tokens.shape[1]\n",
    "\n",
    "            unmerge_buf = TokenUnmergeBuffer(buffer=buffer,\n",
    "                                             active_mask=active_mask,\n",
    "                                             merges=merge_history,\n",
    "                                             n_original=n_original_tokens)\n",
    "\n",
    "            while not unmerge_buf.is_done():\n",
    "                merged_token = unmerge_buf.get_next_to_unmerge()\n",
    "                pred = model.decode(merged_token)\n",
    "                t1_pred, t2_pred = torch.chunk(pred, 2, dim=-1)\n",
    "                unmerge_buf.step_unmerge(t1_pred, t2_pred)\n",
    "            reconstructed = unmerge_buf.get_original_tokens()\n",
    "            \n",
    "            if recon_samples is None:\n",
    "                recon_samples = reconstructed\n",
    "\n",
    "            if not capture_done:\n",
    "                # b=0 sample trajectory\n",
    "                orig_traj = raw_tokens[b, :, :2]\n",
    "                recon_traj = reconstructed[b, :, :2]   # NOTE: move reconstruction before visualisation\n",
    "\n",
    "                fig_merge = plot_merge_event_full(\n",
    "                    tokens_2d=tokens_2d,\n",
    "                    prob_matrix=token_prob_matrix,\n",
    "                    chosen_i=chosen_i,\n",
    "                    chosen_j=chosen_j,\n",
    "                    orig_traj=orig_traj,\n",
    "                    recon_traj=recon_traj,\n",
    "                    merged_token_2d=merged_token_2d,\n",
    "                    highlight_recon_idx=(local_t1_idx[b].item(), local_t2_idx[b].item())\n",
    "                )\n",
    "\n",
    "                wandb.log({f\"merge_event\": wandb.Image(fig_merge)})\n",
    "                plt.close(fig_merge)\n",
    "                capture_done = True\n",
    "\n",
    "\n",
    "            loss = criterion(reconstructed, raw_tokens)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        val_loss = evaluate(model, val_loader, device, config.sampling_policy, current_depth, criterion, config.temperature)\n",
    "        \n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "                \n",
    "        if checkpoint_path and val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "            # fig = visualise(orig_samples, recon_samples) \n",
    "            \n",
    "            orig_samples = [orig_samples[i] for i in range(5)]\n",
    "            recon_samples = [recon_samples[i] for i in range(5)]\n",
    "            fig = visualise_multiple(orig_samples, recon_samples)\n",
    "\n",
    "            # process_fig = visualise_merge_progress(orig_samples[0], merge_snapshots_per_sample[0])\n",
    "\n",
    "\n",
    "        # --- FINAL VISUALISATIONS FOR THE EPOCH ---\n",
    "\n",
    "        # if \"token_prob_matrix_frames\" in locals() and len(token_prob_matrix_frames) > 0:\n",
    "        #     last_matrix = token_prob_matrix_frames[-1]\n",
    "        #     fig1 = plot_token_matrix(last_matrix, title=\"Token merge matrix (final step)\")\n",
    "        #     wandb.log({\"merge_matrix_final\": wandb.Image(fig1)})\n",
    "        #     plt.close(fig1)\n",
    "\n",
    "        #     token_prob_matrix_frames.clear()\n",
    "        # if \"token_position_frames\" in locals() and len(token_position_frames) > 0:\n",
    "        #     tokens_2d, ci, cj = token_position_frames[-1]\n",
    "        #     fig1 = plot_token_positions(tokens_2d, ci, cj,\n",
    "        #                             title=f\"Token positions (final step, merged {ci},{cj})\")\n",
    "        #     wandb.log({\"token_positions_final\": wandb.Image(fig1)})\n",
    "        #     plt.close(fig1)\n",
    "\n",
    "        #     token_position_frames.clear()\n",
    "\n",
    "\n",
    "\n",
    "        log_dict = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"epoch\": epoch,\n",
    "        \"merge_depth\": current_depth,\n",
    "        }\n",
    "\n",
    "        # if 'corr_fig' in locals() and corr_fig is not None:\n",
    "        #     log_dict['softmax_corr_matrix'] = wandb.Image(corr_fig)\n",
    "        \n",
    "        # if 'fig' in locals() and fig is not None:\n",
    "        #     log_dict[\"reconstruction_plot\"] = wandb.Image(fig)\n",
    "        \n",
    "        # if 'scheduler' in locals():\n",
    "        #     log_dict[\"lr\"] = scheduler.get_last_lr()[0]\n",
    "\n",
    "        # TODO: is broken\n",
    "        # if 'process_fig' in locals() and process_fig is not None:\n",
    "        #     log_dict[\"merge_progress_plot\"] = wandb.Image(process_fig)\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "        # TODO: did stupid shit, is on timeout  \n",
    "        # if stopper.should_stop(val_loss):\n",
    "        #     print(f\"Early stopping at epoch {epoch}\")\n",
    "        #     break\n",
    "\n",
    "        \n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d359915",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8e588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfhahn\u001b[0m (\u001b[33mfabianhahn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/export/home/2jhahn/htm/wandb/run-20251204_200547-0rxl9kel</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fabianhahn/random-walker/runs/0rxl9kel' target=\"_blank\">sanity-softmax-0.5-lr-0.0001-merges-1</a></strong> to <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fabianhahn/random-walker/runs/0rxl9kel' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker/runs/0rxl9kel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>merge_depth</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>merge_depth</td><td>1</td></tr><tr><td>train_loss</td><td>0.00174</td></tr><tr><td>val_loss</td><td>0.00203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sanity-softmax-0.5-lr-0.0001-merges-1</strong> at: <a href='https://wandb.ai/fabianhahn/random-walker/runs/0rxl9kel' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker/runs/0rxl9kel</a><br> View project at: <a href='https://wandb.ai/fabianhahn/random-walker' target=\"_blank\">https://wandb.ai/fabianhahn/random-walker</a><br>Synced 5 W&B file(s), 100 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251204_200547-0rxl9kel/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_dim = 2\n",
    "hidden_dim = 128\n",
    "merges = 1\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    epochs=100,\n",
    "    learning_rate=1e-4,\n",
    "    sampling_policy=\"softmax\",\n",
    "    batch_size=128,\n",
    "    device=device,\n",
    "    model_name=f\"sanity-softmax-0.5-lr-{1e-4}-merges-{merges}\",\n",
    "    max_depth=merges,\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "model = AE_no_lift(\n",
    "    token_dim=token_dim,\n",
    "    hidden_dim=hidden_dim\n",
    "    ).to(device)\n",
    "\n",
    "train(model, train_loader, val_loader, config, device, checkpoint_path=f\"./checkpoints/{config.model_name}.pth\", max_depth=merges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
